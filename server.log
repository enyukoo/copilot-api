nohup: ignoring input
ℹ Using VSCode version: 1.104.2
ℹ Logged in as enyukoo
ℹ Available models: 
- gpt-4.1
- gpt-5-mini
- gpt-5
- gpt-3.5-turbo
- gpt-3.5-turbo-0613
- gpt-4o-mini
- gpt-4o-mini-2024-07-18
- gpt-4
- gpt-4-0613
- gpt-4-0125-preview
- gpt-4o
- gpt-4o-2024-11-20
- gpt-4o-2024-05-13
- gpt-4-o-preview
- gpt-4o-2024-08-06
- o3-mini
- o3-mini-2025-01-31
- o3-mini-paygo
- gpt-41-copilot
- grok-code-fast-1
- gpt-5-codex
- text-embedding-ada-002
- text-embedding-3-small
- text-embedding-3-small-inference
- claude-3.5-sonnet
- claude-3.7-sonnet
- claude-3.7-sonnet-thought
- claude-sonnet-4
- gemini-2.0-flash-001
- gemini-2.5-pro
- o4-mini
- o4-mini-2025-04-16
- gpt-4.1-2025-04-14

 ╭──────────────────────────────────────────────────────────────────────────────────────────────╮
 │                                                                                              │
 │  🌐 Usage Dashboards:                                                                        │
 │     • Built-in: http://localhost:4141/dashboard                                              │
 │     • External: https://ericc-ch.github.io/copilot-api?endpoint=http://localhost:4141/usage  │
 │                                                                                              │
 ╰──────────────────────────────────────────────────────────────────────────────────────────────╯

✔ 🚀 Server running on http://localhost:4141
ℹ Press Ctrl+C to stop the server gracefully
✔ 🚀 Server running on http://localhost:4141
ℹ Press Ctrl+C to stop the server gracefully
<-- POST /v1/chat/completions
ℹ Current token count: { input: 11, output: 3 }
--> POST /v1/chat/completions [32m200[0m 1s
<-- GET /v1/models
--> GET /v1/models [32m200[0m 3ms
<-- GET /health
--> GET /health [32m200[0m 1ms
<-- POST /v1/chat/completions
ℹ Current token count: { input: 15, output: 3 }
--> POST /v1/chat/completions [32m200[0m 3s
<-- POST /v1/chat/completions
ℹ Current token count: { input: 130, output: 3 }
--> POST /v1/chat/completions [32m200[0m 4s
<-- GET /usage
--> GET /usage [32m200[0m 461ms
<-- GET /v1/usage
--> GET /v1/usage [33m404[0m 1ms
<-- GET /usage
--> GET /usage [32m200[0m 398ms
<-- GET /health
--> GET /health [32m200[0m 1ms
<-- GET /
--> GET / [32m200[0m 1ms
<-- GET /analytics
--> GET /analytics [32m200[0m 1ms
<-- GET /token
--> GET /token [32m200[0m 1ms
<-- GET /v1/models
--> GET /v1/models [32m200[0m 1ms
<-- POST /v1/chat/completions
ℹ Current token count: { input: 11, output: 3 }
--> POST /v1/chat/completions [32m200[0m 1s
<-- GET /usage
--> GET /usage [32m200[0m 362ms
<-- GET /analytics
--> GET /analytics [32m200[0m 1ms
<-- GET /health
--> GET /health [32m200[0m 1ms
